---
description: AI rules derived by SpecStory from the project AI interaction history
globs: *
---

## HEADERS

## PROJECT RULES

*   Project name: –•—Ä–æ–Ω—ñ–∫–∏ –ü–æ–º–∏–π–∫–∏ (Chronicles of the Dumpster) - A Ukrainian Telegram Card Game Bot.
*   Target Locale: Ukrainian ("uk")

## TECH STACK

*   Python: 3.14
*   aiogram: 3.x -> 3.17 (>=3.17,<4.0)
*   SQLAlchemy: Async
*   PostgreSQL: 17-alpine
*   Redis: alpine
*   Docker Compose
*   pydantic-settings
*   asyncpg
*   alembic
*   apscheduler
*   google-genai: >=1.0.0 -> 1.56.0 (Strict versioning)
*   pydantic: >=2.10 (>=2.10,<3.0)
*   redis: ^5.2.0 (>=5.2.0,<6.0)
*   Pillow >=10.0.0
*   imageio[ffmpeg] >=2.31.0 (For MP4 encoding) Requires ffmpeg binary to be installed on the system.
*   opencv-python>=4.8.0 (Alternative video encoding option) Requires ffmpeg binary to be installed on the system.
*   numpy>=1.24.0
*   aiosqlite>=0.20.0

## PROJECT DOCUMENTATION & CONTEXT SYSTEM

*   `.env.example`: Contains example environment variables: `BOT_TOKEN` (required), `DB_URL` (required), `REDIS_URL` (required), `GEMINI_API_KEY` (optional, bot can run without it), `LOCALE` (defaults to "uk"), `ADMIN_USER_IDS` (comma-separated list of Telegram user IDs, for admin authentication).
*   Context: Using the "Gemini 3.0" feature set which requires the 1.56 SDK.
*   Game Design Document (GDD): `plan-doc.md` - a complete map of mechanics, economics, and logic, which combines already written code with new ideas (trading, currency, battles).
*   Chat Export Format: Telegram JSON export (result.json from Telegram Desktop).
*   Chat Export Location: `data/chat_exports/` directory. Place `result.json` files from Telegram Desktop exports there.
*   To make the `data/chat_exports` folder accessible from the container, add a volume mount in `docker-compose.yml` to mount the directory on the host to `/app/data/chat_exports` inside the container:
    ```yaml
    volumes:
      - ./data/chat_exports:/app/data/chat_exports
      - ./assets:/app/assets
    ```
    *   The `data/chat_exports` directory on the host is mounted into the container at `/app/data/chat_exports/`. Place JSON files in `data/chat_exports/` on your host machine, and they are automatically accessible inside the container at `/app/data/chat_exports/`. No need to copy files into the container or rebuild images.
    *   The `./assets` directory on the host is mounted into the container at `/app/assets`. This allows the container to access and modify card assets.
*   The contents of the chat export folder (specifically *.json and *.txt files) must be added to `.gitignore`.
*   Card Placeholder Specification: `CARD_PLACEHOLDER_SPEC.md` - Defines the layout, data fields, and visual style for generating a placeholder card image resembling Pokemon TCG cards, used for generative editing.
    *   The specification includes the following fields: Card Name, Rarity Indicator, Biome Type, Artwork Area, Attack Stat (ATK), Defense Stat (DEF), Meme Stat, Lore/Flavor Text.
    *   **Rarity Indicators**:
        *   Common (‚ö™)
        *   Rare (üîµ)
        *   Epic (üü£)
        *   Legendary (üü†)
        *   Mythic (üî¥)
    *   **Biome Types**:
        *   –ó–≤–∏—á–∞–π–Ω–∏–π (üåç)
        *   –í–æ–≥–Ω—è–Ω–∏–π (üî•)
        *   –í–æ–¥–Ω–∏–π (üíß)
        *   –¢—Ä–∞–≤'—è–Ω–∏–π (üåø)
        *   –ü—Å–∏—Ö—ñ—á–Ω–∏–π (üîÆ)
        *   –¢–µ—Ö–Ω–æ (‚öôÔ∏è)
        *   –¢–µ–º–Ω–∏–π (üåë)
*   Card Placeholder Files: Empty `.webp` files (with transparent backgrounds) for different card types (biome/rarity/type) are located in dedicated folders. These placeholders will be replaced with generated content.
    *   Placeholders should be named with the format: `assets/placeholders/{biome}_{rarity}.webp`.
    *   If there isn't a proper template in the `assets\placeholders` (non-empty, fully correct WebP normal ones), it must use the one that's fully correct.
        *   Placeholder files must be non-empty to be considered valid. The minimum file size is 1KB. If a biome-specific placeholder is missing or empty, the system must fallback to using the `NORMAL_{rarity}.webp` placeholder.
*   AI Studio Prompts: `PROMPTS_FOR_AI_STUDIO.md` - Contains JSON prompts for generating card template placeholders using Gemini / Imagen 3 in AI Studio.
    *   The file contains JSON prompts for generating card template placeholders using Gemini / Imagen 3 in AI Studio.
    *   To use the prompts:
        1.  Copy the `prompt` text for the specific card template you want to generate.
        2.  Go to [Google AI Studio](https://aistudio.google.com/).
        3.  Select the **Imagen 3** model (or latest image generation model).
        4.  Paste the prompt into the prompt box.
        5.  Set aspect ratio to **Portrait** (3:4) or similar vertical ratio.
        6.  Generate the image.
        7.  Save the image as the corresponding `filename` in `assets/placeholders/`.
    *   The prompts now include the following EXACT layout and text labels:
        *   Biome indicators: `üåç –ó–≤–∏—á–∞–π–Ω–∏–π`, `üî• –í–æ–≥–Ω—è–Ω–∏–π`, `üíß –í–æ–¥–Ω–∏–π`, `üåø –¢—Ä–∞–≤'—è–Ω–∏–π`, `üîÆ –ü—Å–∏—Ö—ñ—á–Ω–∏–π`, `‚öôÔ∏è –¢–µ—Ö–Ω–æ`, `üåë –¢–µ–º–Ω–∏–π`
        *   Rarity indicators: `‚ö™ COMMON`, `üîµ RARE`, `üü£ EPIC`, `üü† LEGENDARY`, `üî¥ MYTHIC`
        *   Card name placeholder: `"–ù–ê–ó–í–ê –ö–ê–†–¢–ö–ò"`
        *   Lore text: `"–¶–µ –æ–ø–∏—Å–æ–≤–∞ —á–∞—Å—Ç–∏–Ω–∞ –∫–∞—Ä—Ç–∫–∏. –í–æ–Ω–∞ –º—ñ—Å—Ç–∏—Ç—å –ª–æ—Ä —Ç–∞ —ñ—Å—Ç–æ—Ä—ñ—é –ø–µ—Ä—Å–æ–Ω–∞–∂–∞."`
        *   Stats with emojis: `‚öîÔ∏è ATK: 50`, `üé≠ MEME: 50`, `üõ°Ô∏è DEF: 50`
    *   Each card template includes the following sections (Pokemon TCG style):
        1.  **Header**: Biome indicator (top left), Card name (top center), Rarity indicator (top right)
        2.  **Artwork Area**: Large center section for character/creature illustration
        3.  **Attacks Section**: 1-2 attacks with energy cost, damage, and effect descriptions
            *   Common cards: 1 attack
            *   Rare+ cards: 2 attacks
            *   Format: Attack name [energy icons] damage
            *   Effect text below each attack in small italic font
        4.  **Lore**: Flavor text in Ukrainian (small italic font)
        5.  **Stats**: ATK (left), MEME (center), DEF (right)
        6.  **Footer**: Weakness (bottom left), Resistance (bottom right), Print date (bottom center)
*   Video Effects Templates: `VIDEO_EFFECTS_TEMPLATES.md` - Outlines video animation effects for card animations.
*   Test Suite Readme: tests/README.md - Provides instructions on how to run the test suite.
*   Resolution: Use 1080p resolution (1080x1920 portrait). Only use .webp files.

## CODING STANDARDS

*   Use `pydantic-settings` for configuration management.
*   Output logs in JSON format using `structlog`.
*   The application must be runnable without the Gemini API key being present (manual adding is acceptable). When `GEMINI_API_KEY` is not provided, Gemini-related functionality should be gracefully disabled.
*   When tracking group chats in `middlewares/group_tracker.py`, use PostgreSQL's `INSERT ON CONFLICT DO NOTHING` to prevent errors when the bot joins a group it has already been in.
*   All Admin prompts should be in Ukrainian.
*   Escape special Markdown V2 characters in user-provided content (card names, usernames, rarity/biome values, user first names) to prevent parsing errors. Use `utils/text.py` with `escape_markdown()`.
*   The bot should primarily edit messages instead of sending new ones to reduce spam. Callback handlers should only edit existing messages, never send new ones.
*   When parsing `ADMIN_USER_IDS` from the environment variables, the validator in `config.py` must handle:
    *   Quoted values (`"392817811"` or `'392817811'`)
    *   Extra whitespace
    *   Invalid entries (log a warning instead of failing)
    *   Single `int` values (e.g., `392817811`)
*   Admin access must be available via username or userID.
*   When using `CallbackData.pack()`, be aware that it uses colons (`:`) as field separators. To avoid `ValueError: Separator symbol ':' can not be used in value` due to Telegram's 64-byte limit on callback data, store the relevant data in Redis using the `SessionManager` and pass only the UUID in the callback.
*   Card Art Style:
    *   The card art style should resemble Pokemon TCG cards, not "cyberpunk trash."
*   Card Generation:
    *   Card generation will use Image Integration Strategy: Option A (AI-driven). The "Nano Banana Pro" (Gemini 3 Pro) model accepts the placeholder and user photo as inputs to generate the final card image directly. However, the image generation model (`gemini-3-pro-image-preview`) accepts images as base64 encoded data in the `contents` array in addition to text prompts.
    *   The card generation process when a user sends an image and description with the `/autocard` command must follow this flow:
        1.  The user sends the message with the `/autocard` command.
        2.  The image and description get sent to the Flash model.
        3.  The JSON result, the sent image, and the correct (non-empty) placeholder get sent to the Nano Banana Pro model, which is instructed to generate (edit the placeholder) with the provided description and reference image.
    *   `CardGeneratorService` (formerly `NanoBananaService`) will use group chat photo/user photo (if available) to generate card illustrations.
    *   `CardGeneratorService` should generate appropriate gradient accents for cards.
    *   `CardGeneratorService` must integrate the photo into the card design.
    *   The bot should send 200 random messages from that user (either from imported messages data or group chat messages), filtered to be at least 20 characters long, to the AI architect to inform card design.
    *   When fetching 200 random messages, mix imported `result.json` data and `MessageLog` (DB) if both are available.
*   Getting Group Chat Icon:
    *   Use `bot.get_chat(chat_id)` to get chat object.
    *   Access the `photo` field of the chat object.
    *   Use `bot.get_file()` and `bot.download_file()` to download the image.
*   Getting User Profile Picture:
    *   Use `bot.get_user_profile_photos(user_id=user_id, limit=1)` to get the most recent profile picture.
    *   Use `bot.get_file()` and `bot.download_file()` to download the image.
    *   This works even if the user isn't registered, as long as the bot has access to them and they have a profile picture set.
*   Unique Card IDs:
    *   Each `UserCard` instance must have a unique, short, human-readable ID (`display_id`).
    *   The `display_id` should have the format "POM-XXXX" where XXXX is a 4-character alphanumeric code.
    *   Characters to use for display IDs: `ABCDEFGHJKLMNPQRSTUVWXYZ2346789` (avoiding confusing characters like 0/O, 1/I, 5/S).
*   Card Border Effects:
    *   Cards should have decorative borders based on rarity.
        *   COMMON - Simple light gray border
        *   RARE - Double blue border
        *   EPIC - Ornate purple border with glow and decorative elements
        *   LEGENDARY - Ornate gold/orange border with glow and corner decorations
        *   MYTHIC - Ornate red border with glow and corner decorations
    *   Rounded corners should be applied.
*   Cards are sent as normal images, and animated ones as MP4 videos (sent as animations). Telegram prefers `.mp4` (H.264) sent as an animation. It will play smoother and load faster than a legacy GIF.
    *   Common/Rare cards: Send as photos
    *   Epic/Legendary/Mythic cards: Send as MP4 videos (sent as animations)
    *   Animated cards must have a frame rate of 20 fps and be slowed down.
*   `/autocard` Photo Generation:
    *   The `/autocard` command now supports generating cards using photos.
    *   Photos can be sent directly with the `/autocard` command (with or without a caption) or by replying to a message containing a photo.
    *   If a caption is provided with the photo, it will be used as a description during blueprint generation.
    *   The `CardGeneratorService` will use the provided photo (if available) instead of the user's profile picture.
    *   When using `/autocard` with a photo but no user is specified (either by replying or with a username/userID in the caption), the message sender will be used as the target.
    *   Generation is allowed with only a photo and description, even without user messages.
*   Card Naming: The card name should be generated on the context, not on the user's name. It can be absolutely custom - the model should be able to generate it.
*   Generated cards must have options to:
    *   Regenerate the image (keeping the same blueprint data).
    *   Edit all fields (stats, name, biome, rarity, lore, attacks, etc.) manually, which should then automatically regenerate the image.
    *   These options should be available before the "Confirm and add/cancel" stage.
    *   When regenerating the image, the blueprint data (name, stats, lore) must be kept, and only the image should be regenerated.
    *   When editing manually, all fields (stats, name, biome, rarity, lore) should be editable.
    *   After editing stats/fields, the image must automatically regenerate with the new data.
*   **Image and Description Consistency**: When generating cards using the `/autocard` command with a photo, the generated card description and lore must accurately reflect the content of the provided photo. The AI should prioritize analyzing the photo to generate the card's description and lore, using user messages and context as secondary information. The system instruction in `services/ai_architect.py` emphasizes this requirement:
    *   "PHOTO ANALYSIS (CRITICAL):
        *   If a photo/image is provided in the context, you MUST analyze it carefully and base the card's description, lore, and visual prompt on what you see in the photo
        *   The photo content should be the PRIMARY source for card generation - describe what's actually visible in the image
        *   The lore_ua should accurately describe what's shown in the photo (people, objects, setting, mood, etc.)
        *   The raw_image_prompt_en should describe the visual elements you see in the photo
        *   The card_name_ua should be inspired by what's in the photo
        *   User messages and context are SECONDARY when a photo is provided - use them only for supplementary thematic elements
        *   If no photo is provided, base the card on user messages and context as usual"
*   **Card Info Generation**: All card info must be correctly generated and synced, including the card "production" date, which must be specified in the prompt. The prompt in `services/ai_architect.py` MUST include the current month/year in MM/YYYY format.
    *   The `print_date` field MUST be set to exactly '{current_print_date}' (current month/year in MM/YYYY format). Do not use any other date.
*   Meme Stat: The AI generates `stats_meme` (0-100), reflecting the playful nature of the game. It MUST be included during conversion from AI blueprint to local CardBlueprint and when saving to the database.
*   **Graceful Callback Handling**: Implement `utils/telegram_utils.py` with a `safe_callback_answer` function to handle "query is too old" TelegramBadRequest errors in callback queries. Replace all instances of `callback.answer` with `safe_callback_answer(callback)` in handler files (`handlers/admin_autocard.py`, `handlers/admin.py`, `handlers/battles.py`, `handlers/drops.py`, `handlers/player.py`, and `handlers/trading.py`). Ensure to add necessary imports from `utils/telegram_utils.py`.
*   **Animated Card Video Effects**: The video effects for animated cards must have a duration of 5 seconds and be looped.
*   **Media Message Handling**: When editing messages, the bot must use `edit_caption()` for photo/animation/video messages and `edit_text()` for text messages. Specifically, in `handlers/admin_autocard.py`:
    *   In `handle_autocard_approve`, update the condition checking `callback.message.photo` to also include `callback.message.animation` and `callback.message.video`.
    *   Use `edit_caption` if any of these media types are present.
    *   Fallback to `edit_text` only if it's strictly a text message (or doesn't match media types).
    *   This logic should mirror the logic already present in `handle_autocard_cancel`.
*   **Card Text Generation**: Ensure the image generation model incorporates blueprint text fields by including all necessary blueprint JSON fields in the prompt. The `card_render_prompt` should be used instead of `raw_image_prompt_en` to include card names, stats and lore. If the AI struggles to accurately render text, consider using Pillow to overlay the text on the generated image. This provides more deterministic control over text rendering.
*   **User-Friendly Editing**: Implement inline keyboard buttons for editing generated cards, replacing the raw JSON editing. The options should include "Edit name", "Edit biome", and "Edit stats". After any edits, the image should automatically regenerate with updated information.
*   **`forge_card_image` Function**: The `forge_card_image` function should accept card fields or a "card_text" structure to ensure necessary values are provided for image generation.
*   **Placeholder Image Conversion**: Convert all PNG placeholders in `assets/placeholders/` to WebP format. A script `convert_placeholders_to_webp.py` should be created to handle this conversion and apply borders to the outputs.
*   `/addcard` Command Enhancement:
    *   `/addcard` is an alias for the existing `/newcard` command.
    *   Modify the `/addcard` command to allow manual card creation by either:
        *   Generating an image via AI, as before.
        *   Uploading a custom image.
    *   Implement a manual flow with simple stats editing, name, and other relevant fields.
    *   The `/addcard` implementation and how it currently generates images should be located.
    *   Add a "manual flow" where the user can either generate an image or upload one.
    *   Include a simple "edit stats/name/etc" step before saving.
    *   After selecting a biome, the bot should ask to choose the image method (generate or upload).
    *   The user should enter ATK, then DEF, then the rarity should be selected via buttons.

## WORKFLOW & RELEASE RULES

*   Bot should primarily edit messages instead of sending new ones to reduce spam.
*   If running the bot in Docker, restart the container after changing environment variables for the changes to take effect. Use `docker-compose restart bot` or `docker-compose up -d --build bot`.
*   Since `display_id` is a new required field, you'll need to:
    1.  Run a database migration to add the column.
    2.  Populate display IDs for any existing cards in the database.
*   The Dockerfile must install `ffmpeg`.

## DEBUGGING

*   `EditMessageText` expects `InlineKeyboardMarkup`, but a `ReplyKeyboardMarkup` is being passed. Editing messages only supports inline keyboards. Ensure that `safe_edit_text()` and Telegram's `edit_text()` are called with `InlineKeyboardMarkup` when editing messages.
*   When debugging admin command access, check the following:
    *   The `.env` file format should be `ADMIN_USER_IDS=392817811` (no quotes, no spaces around the `=`).
    *   Check the logs at startup to verify what admin IDs were loaded.
    *   When attempting the command, check the logs to see what user ID is being checked and what admin IDs are configured.
*   If the callback data exceeds Telegram's 64-byte limit, store the data in Redis using the `SessionManager` and pass only the UUID in the callback.
*   When editing the photo message caption in `handlers/admin_autocard.py` with `edit_text`, ensure that the `chat_id` and `message_id` are correctly passed and that the caption is properly formatted and escaped. The handlers `handle_autocard_cancel` and `handle_autocard_approve` should be reviewed for potential issues. Specifically:
    *   Ensure that the code checks if the message is a photo (`callback.message.photo`) or animation (`callback.message.animation`) or video (`callback.message.video`).
    *   Use `edit_caption()` for photo/animation/video messages.
    *   Use `edit_text()` for text messages.
    *   Ensure all user provided text is escaped using `escape_markdown()`.
*   Missing `datetime` import in `services/ai_architect.py`
*   Schema fix worked: blueprint generation succeeded (line 877). Image generation is failing with "Unable to process input image". Adding image validation and format detection: Unable to process input image. Adding image validation and format detection:
*   Investigate animated GIF playback issues. Desktop TG app shows them as gifs but doesn't autoplay, mobile shows them as broken and as videos. Research the documentation used for sending the media, etc.
    *   **Analysis and Fixes**:
        *   **Problem**:
            *   Desktop TG: Shows animations as GIFs but doesn't autoplay
            *   Mobile TG: Shows animations as broken and displays them as videos
        *   **Root Cause Analysis**:
            *   The bot generates MP4 files using ffmpeg with these parameters:
                *   Codec: H.264 (libx264)
                *   Pixel Format: yuv420p
                *   Frame Rate: 20 fps
                *   movflags: faststart
                *   No audio track
            *   The bot sends them using `answer_animation()` method, which is correct.
            *   Identified Issues:
                1.  **Missing Loop Flag in MP4**: Telegram needs MP4 files to have explicit loop metadata. The current ffmpeg command doesn't set the loop count in the MP4 container.
                    *   Fix: Add `-stream_loop -1` (infinite loop) flag to ffmpeg command.
                2.  **Missing Duration Parameter**: When sending animations via `answer_animation()`, Telegram benefits from knowing the duration upfront.
                    *   Fix: Calculate and pass `duration` parameter to `answer_animation()`.
                3.  **Possible Profile/Level Issues**: H.264 profile and level might affect compatibility across different Telegram clients.
                    *   Fix: Explicitly set H.264 profile to `baseline` or `main` for maximum compatibility.
                4.  **Filename Extension Confusion**: Sending MP4 files might confuse some Telegram clients. Telegram officially supports both MP4 and GIF for animations.
                    *   Fix: Consider adding explicit `filename` parameter with `.gif` extension when sending MP4 animations.
                5.  **Missing Width/Height Parameters**: Not specifying width and height might cause display issues on some clients.
                    *   Fix: Pass `width` and `height` to `answer_animation()`.
        *   **Proposed Solutions**:
            1.  **Improve MP4 Encoding (Recommended)**:
                *   Modify the ffmpeg command in `services/card_animator.py` to:
                    ```bash
                    ffmpeg -framerate 20 -i frame_%04d.png \
                      -c:v libx264 -profile:v baseline -level 3.0 \
                      -pix_fmt yuv420p \
                      -vf "scale=trunc(iw/2)*2:trunc(ih/2)*2" \
                      -movflags +faststart \
                      -loop 0 \
                      -an \
                      -y output.mp4
                    ```
            2.  **Add Metadata to answer_animation()**:
                *   Pass additional parameters:
                    ```python
                    await message.answer_animation(
                        animation=animation_file,
                        duration=2,  # Total duration in seconds
                        width=640,   # Actual width
                        height=896,  # Actual height
                        caption=caption,
                        reply_markup=keyboard,
                        parse_mode="Markdown",
                    )
                    ```
            3.  **Try GIF Format Instead**: Fallback to generating actual GIF files using imageio or Pillow if MP4 continues to have issues.
            4.  **Use Video with Loop Flag**: As alternative, send as `answer_video()` with `supports_streaming=True`.
        *   **Recommended Implementation Order**:
            1.  Fix ffmpeg encoding with proper loop and profile flags (high impact, low risk)
            2.  Add duration/width/height to answer_animation() (medium impact, low risk)
            3.  Test with actual GIF generation as fallback (low impact, medium effort)
        *   **Additional Observations**: From the user's message: "–¢—Ä–æ—Ö–∏ –ø–æ—Ö—É–π–æ–≤–∏–ª–æ –±–æ –Ω–µ–∑–∞–∫—ñ–Ω—á–µ–Ω—ñ —Ç–µ–º–ø–ª–µ–π—Ç–∏" suggests there might also be issues with incomplete templates, not just animation format.
    *   **Implementation Status: ‚úÖ COMPLETED**
        *   **Changes Made:**
            1.  **services/card_animator.py**
                *   ‚úÖ Added `-profile:v baseline` for maximum compatibility
                *   ‚úÖ Added `-level 3.0` for H.264 level specification
                *   ‚úÖ Fixed `-movflags` syntax to `+faststart`
                *   ‚úÖ Added `-preset fast` for faster encoding
            2.  **utils/animations.py** (NEW FILE)
                *   ‚úÖ Created `send_card_animation()` helper function
                *   ‚úÖ Automatically extracts width/height from base image
                *   ‚úÖ Sets duration parameter (2 seconds)
                *   ‚úÖ Provides consistent error handling
            3.  **handlers/admin_autocard.py**
                *   ‚úÖ Updated to use `send_card_animation()` helper
                *   ‚úÖ Removed manual `answer_animation()` calls
            4.  **handlers/player.py**
                *   ‚úÖ Updated to use `send_card_animation()` helper
                *   ‚úÖ Improved animation sending in inventory view
            5.  **handlers/admin.py**
                *   ‚úÖ Updated to use `send_card_animation()` helper
                *   ‚úÖ Improved test command animation sending
        *   **Testing Instructions:**
            1.  **Regenerate existing animations** (optional):
                ```bash
                python regenerate_all_animations.py
                ```
            2.  **Generate a new card** with Epic/Legendary/Mythic rarity:
                ```bash
                /autocard @username
                ```
            3.  **Test on Desktop Telegram**:
                *   Animation should autoplay immediately
                *   Should loop continuously
                *   Should display as GIF (not video)
            4.  **Test on Mobile Telegram**:
                *   Animation should autoplay on open
                *   Should not show video player controls
                *   Should loop smoothly
        *   **Expected Results:**
            *   ‚úÖ Desktop: Animations autoplay and loop
            *   ‚úÖ Mobile: Animations display correctly (not as broken videos)
            *   ‚úÖ Both: Smooth playback without stuttering
            *   ‚úÖ File sizes: Smaller than equivalent GIFs
        *   **Rollback Plan (if needed):**
            *   If issues persist, you can:
                1.  Revert ffmpeg changes in `services/card_animator.py`
                2.  Remove `utils/animations.py`
                3.  Restore original `answer_animation()` calls in handlers
                4.  Use GIF format instead of MP4 (set in card_animator.py)
*   **Card Info Generation**: Investigate and fix issues related to incorrect card information generation. This is a high priority.
    *   The image generation model isn't incorporating blueprint text fields, just leaving placeholders. This could be related to the way prompts are structured in the "NanoBanana" service. It seems the final card image generation might not be including necessary blueprint JSON fields in the prompt. It's possible they avoided instructing the model to produce text to prevent inaccuracies, given how generative models handle text.
    *   To fix this, pass full card fields into the image prompt. Extend `ArtForgeService.forge_card_image(...)` and `_generate_image_sync(...)` to accept an optional `card_fields: dict | None`. When a placeholder is used, append a strict ‚ÄúCARD_FIELDS_TO_RENDER‚Äù block to the prompt:
        *   Card name (UA)
        *   Biome label (emoji + UA)
        *   Rarity badge (emoji + UPPERCASE English)
        *   Stats lines: `‚öîÔ∏è ATK`, `üé≠ MEME`, `üõ°Ô∏è DEF`
        *   Attacks list (name/type/damage/energy/effect/status)
        *   Lore (UA)
        *   Print date
        *   Weakness/resistance
    *   Add explicit instructions: ‚Äú**Replace placeholder text** (e.g. `–ù–ê–ó–í–ê –ö–ê–†–¢–ö–ò`, `–ü—Ä–∏–∫–ª–∞–¥ –ê—Ç–∞–∫–∏ ‚Ä¶`, default stats) with these exact values; don‚Äôt invent new text; keep the template layout.‚Äù
    *   Update callers to pass `card_fields`:
        *   `services/nano_banana.py`: build a dict from the generated `CardBlueprint` and pass it into `forge_card_image(...)`.
        *   `handlers/admin_autocard.py`: in `_regenerate_card_image(...)`, pass the Redis `blueprint_data` as `card_fields` so regenerations after edits also render text.
    *   Blueprint updates currently don‚Äôt persist (hidden bug). `SessionManager.store_blueprint()` always creates a new UUID. Current code uses it for ‚Äúupdates‚Äù and ignores the returned ID, so callbacks keep pointing at stale data. To fix this, add `SessionManager.update_blueprint(blueprint_id, blueprint_data, ttl=...)` in `services/session_manager.py` and replace the incorrect ‚Äúupdate via store_blueprint‚Äù calls.
    *   Replace JSON editing with button-driven editor in `handlers/admin_autocard.py`: Replace the current `CardEditStates.waiting_for_json` flow with an inline **edit menu**:
        *   Top-level edit keyboard: `üìõ –ù–∞–∑–≤–∞`, `üåç –ë—ñ–æ–º`, `üíé –†—ñ–¥–∫—ñ—Å—Ç—å`, `üìä –°—Ç–∞—Ç–∏ (ATK/DEF/MEME)`, `üìñ –õ–æ—Ä`, `‚ö° –ê—Ç–∞–∫–∏`, `üñº Prompt`, `üóì –î–∞—Ç–∞`, `‚¨ÖÔ∏è –ù–∞–∑–∞–¥`.
        *   Biome/rarity/type/status selections are done via inline choices (no typing).
        *   Text/number fields prompt the admin for a value (FSM `waiting_for_value`), validate, then regenerate.
        *   After any edit, automatically:
            *   update the Redis blueprint via `update_blueprint`
            *   regenerate the image via `_regenerate_card_image`
            *   update the preview caption (and keep the four main actions available).
    *   Escape Markdown V2 / Markdown special chars when building captions and editor text via `utils/text.py::escape_markdown()`.
    *   Keep callback data short (blueprint_id + small field/value codes) to avoid Telegram 64-byte limits.

## INFRASTRUCTURE

*   Docker Compose should define `bot`, `db` (PostgreSQL), and `redis` services.
*   Docker container must wait for Postgres and Redis to be healthy before starting the bot. This can be achieved through health checks in `docker-compose.yml` and/or retry logic in the Python startup code.
*   Use named volumes for `pg_data` and `redis_data` to persist data.
*   Dockerfile: The `CMD` instruction should be `CMD ["python", "main.py"]` to correctly start the bot application.
*   To make the `data/chat_exports` folder accessible from the container, add a volume mount in `docker-compose.yml` to mount the directory on the host to `/app/data/chat_exports` inside the container:
    ```yaml
    volumes:
      - ./data/chat_exports:/app/data/chat_exports
      - ./assets:/app/assets
    ```
    *   The `data/chat_exports` directory on the host is mounted into the container at `/app/data/chat_exports/`. Place JSON files in `data/chat_exports/` on your host machine, and they are automatically accessible inside the container at `/app/data/chat_exports/`. No need to copy files into the container or rebuild images.
    *   The `./assets` directory on the host is mounted into the container at `/app/assets`. This allows the container to access and modify card assets.
*   The Dockerfile must install `ffmpeg`. The `assets/placeholders/` directory is mounted as a volume to allow the container to modify card assets.

## REDIS

*   Utilize `services/redis_lock.py` with a Lua script for atomic operations to prevent race conditions when claiming drops. The Lua script should:
    *   Atomically check if the drop key exists.
    *   If it doesn't, set the key to the user ID, set a TTL, and return 1.
    *   If it does exist, return 0.
*   Use async Redis (`redis.asyncio`) to match the project's async pattern.
*   Load the script once and cache it via SHA.
*   Implement error handling: return `False` on Redis errors to prevent double claims.
*   Implement `DropManager` class in `services/redis_lock.py` with methods:
    *   `try_claim_drop(message_id, user_id, ttl)`
    *   `release_drop()` - manual cleanup
    *   `get_claim_owner()` - check who claimed a drop
    *   `close()` - cleanup connection
*   Implement `services/session_manager.py` to manage trade and battle sessions.
*   The `SessionManager` should also include methods for storing and retrieving blueprint data for autocard flows, using UUIDs as keys. These methods are:
    *   `store_blueprint(blueprint(blueprint_data: dict, ttl: