---
description: AI rules derived by SpecStory from the project AI interaction history
globs: *
---

## HEADERS

## PROJECT RULES

*   Project name: –•—Ä–æ–Ω—ñ–∫–∏ –ü–æ–º–∏–π–∫–∏ (Chronicles of the Dumpster) - A Ukrainian Telegram Card Game Bot.
*   Target Locale: Ukrainian ("uk")

## TECH STACK

*   Python: 3.14
*   aiogram: 3.x -> 3.17 (>=3.17,<4.0)
*   SQLAlchemy: Async
*   PostgreSQL: 17-alpine
*   Redis: alpine
*   Docker Compose
*   pydantic-settings
*   asyncpg
*   alembic
*   apscheduler
*   google-genai: >=1.0.0 -> 1.56.0 (Strict versioning)
*   pydantic: >=2.10 (>=2.10,<3.0)
*   redis: ^5.2.0 (>=5.2.0,<6.0)

## PROJECT DOCUMENTATION & CONTEXT SYSTEM

*   `.env.example`: Contains example environment variables: `BOT_TOKEN` (required), `DB_URL` (required), `REDIS_URL` (required), `GEMINI_API_KEY` (optional, bot can run without it), `LOCALE` (defaults to "uk"), `ADMIN_USER_IDS` (comma-separated list of Telegram user IDs, for admin authentication).
*   Context: Using the "Gemini 3.0" feature set which requires the 1.56 SDK.

## CODING STANDARDS

*   Use `pydantic-settings` for configuration management.
*   Output logs in JSON format using `structlog`.
*   The application must be runnable without the Gemini API key being present (manual adding is acceptable). When `GEMINI_API_KEY` is not provided, Gemini-related functionality should be gracefully disabled.
*   When tracking group chats in `middlewares/group_tracker.py`, use PostgreSQL's `INSERT ON CONFLICT DO NOTHING` to prevent errors when the bot joins a group it has already been in.
*   All Admin prompts should be in Ukrainian.

## WORKFLOW & RELEASE RULES

## DEBUGGING

## INFRASTRUCTURE

*   Docker Compose should define `bot`, `db` (PostgreSQL), and `redis` services.
*   Docker container must wait for Postgres and Redis to be healthy before starting the bot. This can be achieved through health checks in `docker-compose.yml` and/or retry logic in the Python startup code.
*   Use named volumes for `pg_data` and `redis_data` to persist data.
*   Dockerfile: The `CMD` instruction should be `CMD ["python", "main.py"]` to correctly start the bot application.

## REDIS

*   Utilize `services/redis_lock.py` with a Lua script for atomic operations to prevent race conditions when claiming drops. The Lua script should:
    *   Atomically check if the drop key exists.
    *   If it doesn't, set the key to the user ID, set a TTL, and return 1.
    *   If it does exist, return 0.
*   Use async Redis (`redis.asyncio`) to match the project's async pattern.
*   Load the script once and cache it via SHA.
*   Implement error handling: return `False` on Redis errors to prevent double claims.
*   Implement `DropManager` class in `services/redis_lock.py` with methods:
    *   `try_claim_drop(message_id, user_id, ttl)`
    *   `release_drop()` - manual cleanup
    *   `get_claim_owner()` - check who claimed a drop
    *   `close()` - cleanup connection

## MIDDLEWARE

*   Implement `middlewares/group_tracker.py` to track group chats.
*   Create `ChatTrackingMiddleware` that intercepts every update.
*   If `chat.type` is `supergroup` or `group`:
    *   Upsert the `GroupChat` table (INSERT ON CONFLICT DO NOTHING). This ensures we have a list of all groups the bot is in.
*   Implement `middlewares/logger.py` to log messages in group chats.
    *   Create a new middleware that runs after `GroupTrackingMiddleware`.
    *   **Logic**: For every text message in a group chat:
        *   Fire-and-forget an async task to insert the message into `MessageLog`.
    *   **Optimization**: Do *not* log commands (starting with `/`).

## HANDLERS

*   Create `handlers/drops.py` to handle drop claims.
    *   **Import Fix**: Use `from aiogram.filters.callback_data import CallbackData` instead of `from aiogram.filters import CallbackData`.
    *   **Loop Fix**: In `_award_card_and_update_message`, remove the `finally:` block and move the `break` statement to the end of the `try` block.
*   Implement a Callback Query Handler for data `claim_drop`.
*   Call `DropManager.try_claim_drop(message.message_id, user.id)`.
    *   **If Success**:
        *   Award card to user in DB.
        *   Edit message text: "‚úÖ **[User]** –±–ª–∏—Å–∫–∞–≤–∏—á–Ω–æ —Å—Ö–æ–ø–∏–≤ [Card Name]!" (Use Ukrainian).
    *   **If Fail**:
        *   Answer callback query with alert: "‚ùå –•—Ç–æ—Å—å –≤–∏—è–≤–∏–≤—Å—è —Å–ø—Ä–∏—Ç–Ω—ñ—à–∏–º!" (Alert/Toast).
*   Create `handlers/admin.py` to handle admin commands.
*   Implement Admin Card Creation Flow in `handlers/admin.py`.
    *   **FSM**: States `WaitingForName`, `WaitingForArtPrompt`, `WaitingForStats`.
    *   `/newcard` -> Input Name.
    *   Select Biome (Inline Keyboard of Biomes).
    *   Input Prompt -> Gen Art -> Review.
    *   Input Stats -> Save.
    *   **Nano Banana Integration**:
        *   Use `NanoBananaService` to generate art.
        *   Prompt: "Trading card art, [User Prompt], style of [Biome Style]".
        *   The `generate_card_image()` function in `handlers/admin.py` generates card image using Nano Banana Pro (Gemini 3 Pro Image).
        *   To complete the image generation, implement the actual API call in `generate_card_image()` based on your image generation service (Nano Banana or another service). The function should return a relative filepath to saved image.
        *   The flow continues even if image generation fails (image_url can be None), allowing cards to be created without images if needed.
*   Implement `handlers/admin_autocard.py`.
    *   Command: `/autocard` (reply to a user's message to target them).
    *   **Logic Flow (Async):**
        1.  **Trigger**: Admin replies `/autocard` to a user message.
        2.  **Feedback**: Bot sends "üïµÔ∏è‚Äç‚ôÇÔ∏è –ê–Ω–∞–ª—ñ–∑—É—é –æ—Å–æ–±–∏—Å—Ç—ñ—Å—Ç—å [User]..." (Analyzing personality...).
        3.  **Fetch Context**:
            *   DB Query: Select last 50 messages from `MessageLog` for this `target_user_id`.
            *   Flatten into a list of strings.
        4.  **Architect Step**:
            *   Bot edits message: "üß† –ü—Ä–æ—î–∫—Ç—É—é –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä—É –∫–∞—Ä—Ç–∫–∏..." (Designing card architecture...).
            *   Call `CardArchitectService.generate_blueprint(logs, target_user_id)`. Pass the `target_user_id` to the service.
        5.  **Art Forge Step**:
            *   Bot edits message: "üé® –ö—É—é –≤—ñ–∑—É–∞–ª —É –Ω–∞–Ω–æ-–≥–æ—Ä–Ω—ñ..." (Forging visuals in nano-forge...).
            *   Call `ArtForgeService.forge_card_image(blueprint.raw_image_prompt_en, blueprint.biome)`.
        6.  **Preview & Confirmation**:
            *   Bot deletes status message.
            *   Send Photo (the generated image) with caption formatted using `blueprint` data (Name, Stats, Lore, Biome emoji).
            *   Attach Inline Keyboard: "‚úÖ –ó–∞—Ç–≤–µ—Ä–¥–∏—Ç–∏ —Ç–∞ –í–∏–¥–∞—Ç–∏" (Approve & Issue) or "‚ùå –°–∫–∞—Å—É–≤–∞—Ç–∏".
        7.  **Finalize (On Button Click)**:
            *   Save `CardTemplate` to DB.
            *   Create `UserCard` for the target user instantly.
            *   Edit message: "üéâ –ö–∞—Ä—Ç–∫—É [Card Name] —Å—Ç–≤–æ—Ä–µ–Ω–æ —Ç–∞ –≤–∏–¥–∞–Ω–æ [User]!"

## DATABASE

*   Use `database/session.py` for database session management.
*   Use `AsyncSession` from SQLAlchemy for asynchronous database operations.
*   Implement `get_session` dependency function to get database session.
*   Modify `database/models.py` to add message logging.
    *   **New Model `MessageLog`**:
        *   `id` (BigInt, PK, auto-increment)
        *   `user_id` (BigInt, FK to User.telegram_id, indexed)
        *   `chat_id` (BigInt, FK to GroupChat.chat_id)
        *   `content` (Text, store truncated message text up to 500 chars)
        *   `created_at` (DateTime, default now, indexed)
            *   Use `insert_default=lambda: datetime.now(timezone.utc)` instead of `default_factory` for non-dataclass SQLAlchemy models.
            *   Must define `DateTime(timezone=True)` as the first argument to `mapped_column` to ensure timezone awareness.
    *   **`UserCard.acquired_at`**:
        *   Use `insert_default=lambda: datetime.now(timezone.utc)` instead of `default_factory` for non-dataclass SQLAlchemy models.
        *   Must define `DateTime(timezone=True)` as the first argument to `mapped_column` to ensure timezone awareness.

## SCHEDULER

*   Implement `services/scheduler.py` using `apscheduler`.
    *   Create `DropScheduler` class using APScheduler's `AsyncIOScheduler`.
    *   Job `trigger_random_drops` runs every X minutes (default: 10, configurable).
    *   Fetches active groups from the database.
    *   For each group (or a random subset):
        *   Roll RNG with configurable chance (default: 5%).
        *   On success:
            *   Calculates biome using `get_chat_biome(chat_id)`.
            *   Selects a random `CardTemplate` where `biome_affinity == biome`.
            *   Sends a message with the specified text and an inline "‚úã –•–∞–ø–Ω—É—Ç–∏" button.
            *   Uses `ClaimDropCallback` with the template ID.
*   Scheduler is configured with:
    *   Interval: 10 minutes (configurable via constructor).
    *   Drop chance: 5% per group (configurable via constructor).
    *   Optional max groups per run limit.
*   The scheduler starts automatically when the bot starts and stops gracefully on shutdown.
*   Integration: Start the scheduler in `main.py` on startup.
*   Create `services/cleanup.py` with daily cleanup job.
    *   **Logic**: `DELETE FROM message_logs WHERE created_at < now() - INTERVAL '7 days'`.
    *   This keeps the database lean, only keeping recent context for generation.

## MAIN APPLICATION

*   Create `main.py` as application entry point that:
    *   Initializes logging and database.
    *   Creates Bot and Dispatcher instances.
    *   Registers routers (drops router, admin router, admin_autocard router).
    *   Registers middlewares (ChatTrackingMiddleware, MessageLoggingMiddleware) - order matters.
    *   Initializes and starts the scheduler on startup.
    *   Handles cleanup on shutdown.
    *   Update `main.py` to register middleware and start cleanup scheduler.
    *   Ensure the startup sequence wraps the `await bot.delete_webhook()` call in a try/except block. If the bot was previously running on a webhook, this can crash the polling startup.

## AI SERVICES

*   Create `services/ai_architect.py`.
    *   Stack: `google-genai`, `pydantic`.
    *   **Define Pydantic Model (`CardBlueprint`)**:
        *   `target_user_id`: int
        *   `card_name_ua`: str
        *   `rarity`: Rarity Enum (Common, Rare, etc.)
        *   `biome`: BiomeType Enum (Techno, Fire, etc.)
        *   `stats_atk`: int (0-100)
        *   `stats_def`: int (0-100)
        *   `stats_meme`: int (0-100)
        *   `lore_ua`: str (2 sentences max)
        *   `raw_image_prompt_en`: str (Descriptive prompt for visual elements only)
    *   **Class `CardArchitectService`**:
        *   Init with `GEMINI_API_KEY`.
        *   Method `generate_blueprint(user_context_logs: list[str]) -> CardBlueprint`:
            *   **System Instruction**: Convert the "Gemini Gem" prompt provided earlier into a Python string. Crucially, emphasize the output must be valid JSON matching the `CardBlueprint` schema.
            *   **Call Gemini**: Use `gemini-3-flash-preview` with `client.models.generate_content` and `generation_config={"response_mime_type": "application/json"}`. Sticking to the default thinking level (which is usually "Dynamic" for Flash 3) is safer for now to avoid 400 Bad Request errors.
            *   **Note**: Using default thinking level for Gemini 3 Flash (usually "Dynamic") to avoid 400 Bad Request errors until SDK fully supports explicit `thinking_config`.
            *   **Parsing**: Use `CardBlueprint.model_validate_json(response.text)` to ensure robust parsing.
            *   **Error Handling**: Catch validation errors and retry once if Gemini hallucinates the schema.
            *   **Call Gemini**: Use `gemini-3-flash-preview` with `client.models.generate_content`.
            *   Use unified SDK with v1.56+ features: native Pydantic support and thinking config
            *   ```python
                            response = self._client.models.generate_content(
                                model=self._model_id,
                                contents=user_message,
                                config=types.GenerateContentConfig(
                                    system_instruction=self._system_instruction,
                                    # Native Pydantic support in v1.56+
                                    response_schema=CardBlueprint,
                                    response_mime_type="application/json",
                                    # Enable Gemini 3.0 "Thinking" (Reasoning)
                                    # "medium" offers the best balance for a game (smarter than low, faster than high)
                                    thinking_config=types.ThinkingConfig(
                                        include_thoughts=False,
                                        thinking_level="medium"
                                    ),
                                    temperature=1.0,
                                )
                            )

                            if not response.parsed:
                                raise ValueError("Gemini 3 failed to return a valid blueprint.")

                            blueprint = response.parsed
            ```
*   Create `services/art_forge.py`.
    *   Stack: `google-genai` (for Gemini 3 Pro Image).
    *   **Style Constants**:
        *   Define a constant string `UNIFORM_STYLE_GUIDE`: "Trading card illustration, cohesive high fantasy cyberpunk fusion art style, ornate border design elements, digital painting, masterpiece, highly detailed, 8k resolution, cinematic lighting, rich textures."
    *   **Class `ArtForgeService`**:
        *   Init with `GEMINI_API_KEY` and store pass for `media/cards/` directory.
        *   Method `forge_card_image(blueprint_prompt: str, biome: BiomeType) -> str (filepath)`:
            *   **Combine Prompt**: f"{UNIFORM_STYLE_GUIDE}. Subject: {blueprint_prompt}. Biome theme: {biome.value}."
            *   **Call API**: Use the Gemini Image Generation model (`gemini-3-pro-image-preview`) and `client.models.generate_content` with `config=types.GenerateContentConfig(response_modalities=["IMAGE"], safety_settings=[types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_ONLY_HIGH"], aspect_ratio="3:4").
            *   **Save**: Save resulting binary to `media/cards/{uuid4()}.png`.
            *   **Return**: Relative path to the saved image.
            *   **Error Handling**: Handle rate limits with exponential backoff.
*   Create `services/nano_banana.py`.
    *   Inherits from `ArtForgeService` to maintain style consistency.
    *   Provides `generate_from_prompt()` method for manual flows.
    *   Uses the same underlying generation logic as `ArtForgeService`.

## UTILS

*   Create `utils/images.py` helper for image saving
    *   Function `save_generated_image(image_bytes: bytes, directory: str = "media/cards") -> str`:
        *   Decodes bytes if needed.
        *   Generates a UUID filename.
        *   Saves to disk.
        *   Returns the relative filepath.